{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e4932d",
   "metadata": {},
   "source": [
    "# RPT (Research Paper Tagger)\n",
    "\n",
    "\n",
    "This Jupyter notebook contains the code that trains RPT. We take a pre-trained BERT model and fine-tune it on the ACL data that we have collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "206dd150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helpers import tokenize_and_format, flat_accuracy\n",
    "\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3758d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found device: NVIDIA GeForce RTX 2060 with Max-Q Design, n_gpu: 1\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "# Confirm that the GPU is detected\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = torch.cuda.get_device_name()\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61150200",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/Raw data/training_data.jsonl\", \"r\") as f:\n",
    "    training_data = json.load(f)\n",
    "    \n",
    "with open(\"Data/Raw data/validation_data.jsonl\", \"r\") as f:\n",
    "    validation_data = json.load(f)\n",
    "    \n",
    "with open(\"Data/Raw data/test_data.jsonl\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    \n",
    "with open(\"Data/Metadata/label_string_to_ID.jsonl\", \"r\") as f:\n",
    "    label_string_to_ID = json.load(f)\n",
    "    \n",
    "with open(\"Data/Metadata/label_ID_to_string.jsonl\", \"r\") as f:\n",
    "    label_ID_to_string = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90675f40",
   "metadata": {},
   "source": [
    "### 1) Prediction using only title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e344cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs_1 = []\n",
    "training_label_strings_1 = []\n",
    "\n",
    "validation_inputs_1 = []\n",
    "validation_label_strings_1 = []\n",
    "\n",
    "test_inputs_1 = []\n",
    "test_label_strings_1 = []\n",
    "\n",
    "for training_example in training_data:\n",
    "    \n",
    "    training_input = training_example[0][0]\n",
    "    training_inputs_1.append(training_input)\n",
    "    \n",
    "    training_label_strings_1.append(training_example[1])\n",
    "    \n",
    "for validation_example in validation_data:\n",
    "    \n",
    "    validation_input = validation_example[0][0]\n",
    "    validation_inputs_1.append(validation_input)\n",
    "    \n",
    "    validation_label_strings_1.append(validation_example[1])\n",
    "    \n",
    "for test_example in test_data:\n",
    "    \n",
    "    test_input = test_example[0][0]\n",
    "    test_inputs_1.append(test_input)\n",
    "    \n",
    "    test_label_strings_1.append(test_example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549b0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_ids_1, training_attention_masks_1 = tokenize_and_format(training_inputs_1, 32)\n",
    "validation_input_ids_1, validation_attention_masks_1 = tokenize_and_format(validation_inputs_1, 32)\n",
    "test_input_ids_1, test_attention_masks_1 = tokenize_and_format(test_inputs_1, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a0a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_IDs_1 = []\n",
    "validation_label_IDs_1 = []\n",
    "test_label_IDs_1 = []\n",
    "\n",
    "for training_label_string in training_label_strings_1:\n",
    "    training_label_IDs_1.append(label_string_to_ID[training_label_string])\n",
    "    \n",
    "for validation_label_string in validation_label_strings_1:\n",
    "    validation_label_IDs_1.append(label_string_to_ID[validation_label_string])\n",
    "    \n",
    "for test_label_string in test_label_strings_1:\n",
    "    test_label_IDs_1.append(label_string_to_ID[test_label_string])\n",
    "    \n",
    "    \n",
    "# Convert the lists into tensors.\n",
    "training_input_ids_1 = torch.cat(training_input_ids_1, dim=0)\n",
    "training_attention_masks_1 = torch.cat(training_attention_masks_1, dim=0)\n",
    "training_label_IDs_1 = torch.tensor(training_label_IDs_1)\n",
    "\n",
    "validation_input_ids_1 = torch.cat(validation_input_ids_1, dim=0)\n",
    "validation_attention_masks_1 = torch.cat(validation_attention_masks_1, dim=0)\n",
    "validation_label_IDs_1 = torch.tensor(validation_label_IDs_1)\n",
    "\n",
    "test_input_ids_1 = torch.cat(test_input_ids_1, dim=0)\n",
    "test_attention_masks_1 = torch.cat(test_attention_masks_1, dim=0)\n",
    "test_label_IDs_1 = torch.tensor(test_label_IDs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c260bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = [(training_input_ids_1[i], training_attention_masks_1[i], training_label_IDs_1[i]) for i in range(len(training_inputs_1))]\n",
    "val_set_1 = [(validation_input_ids_1[i], validation_attention_masks_1[i], validation_label_IDs_1[i]) for i in range(len(validation_inputs_1))]\n",
    "test_set_1 = [(test_input_ids_1[i], test_attention_masks_1[i], test_label_IDs_1[i]) for i in range(len(test_inputs_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = train_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694fdc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 20, # The number of output labels.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8866da11",
   "metadata": {},
   "source": [
    "### Fine-tune the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c08fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 238.47287893295288\n",
      "Validation accuracy: 0.2914285714285714\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 187.71812891960144\n",
      "Validation accuracy: 0.44571428571428573\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 131.93950653076172\n",
      "Validation accuracy: 0.5428571428571428\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 95.32674759626389\n",
      "Validation accuracy: 0.5885714285714285\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 63.866333082318306\n",
      "Validation accuracy: 0.5371428571428571\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 39.54190684854984\n",
      "Validation accuracy: 0.5657142857142857\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 24.896363150328398\n",
      "Validation accuracy: 0.6057142857142858\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 16.20369178056717\n",
      "Validation accuracy: 0.5542857142857143\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n",
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 12.132864885032177\n",
      "Validation accuracy: 0.5771428571428572\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "Batch 0 out of 87 batches.\n",
      "Batch 1 out of 87 batches.\n",
      "Batch 2 out of 87 batches.\n",
      "Batch 3 out of 87 batches.\n",
      "Batch 4 out of 87 batches.\n",
      "Batch 5 out of 87 batches.\n",
      "Batch 6 out of 87 batches.\n",
      "Batch 7 out of 87 batches.\n",
      "Batch 8 out of 87 batches.\n",
      "Batch 9 out of 87 batches.\n",
      "Batch 10 out of 87 batches.\n",
      "Batch 11 out of 87 batches.\n",
      "Batch 12 out of 87 batches.\n",
      "Batch 13 out of 87 batches.\n",
      "Batch 14 out of 87 batches.\n",
      "Batch 15 out of 87 batches.\n",
      "Batch 16 out of 87 batches.\n",
      "Batch 17 out of 87 batches.\n",
      "Batch 18 out of 87 batches.\n",
      "Batch 19 out of 87 batches.\n",
      "Batch 20 out of 87 batches.\n",
      "Batch 21 out of 87 batches.\n",
      "Batch 22 out of 87 batches.\n",
      "Batch 23 out of 87 batches.\n",
      "Batch 24 out of 87 batches.\n",
      "Batch 25 out of 87 batches.\n",
      "Batch 26 out of 87 batches.\n",
      "Batch 27 out of 87 batches.\n",
      "Batch 28 out of 87 batches.\n",
      "Batch 29 out of 87 batches.\n",
      "Batch 30 out of 87 batches.\n",
      "Batch 31 out of 87 batches.\n",
      "Batch 32 out of 87 batches.\n",
      "Batch 33 out of 87 batches.\n",
      "Batch 34 out of 87 batches.\n",
      "Batch 35 out of 87 batches.\n",
      "Batch 36 out of 87 batches.\n",
      "Batch 37 out of 87 batches.\n",
      "Batch 38 out of 87 batches.\n",
      "Batch 39 out of 87 batches.\n",
      "Batch 40 out of 87 batches.\n",
      "Batch 41 out of 87 batches.\n",
      "Batch 42 out of 87 batches.\n",
      "Batch 43 out of 87 batches.\n",
      "Batch 44 out of 87 batches.\n",
      "Batch 45 out of 87 batches.\n",
      "Batch 46 out of 87 batches.\n",
      "Batch 47 out of 87 batches.\n",
      "Batch 48 out of 87 batches.\n",
      "Batch 49 out of 87 batches.\n",
      "Batch 50 out of 87 batches.\n",
      "Batch 51 out of 87 batches.\n",
      "Batch 52 out of 87 batches.\n",
      "Batch 53 out of 87 batches.\n",
      "Batch 54 out of 87 batches.\n",
      "Batch 55 out of 87 batches.\n",
      "Batch 56 out of 87 batches.\n",
      "Batch 57 out of 87 batches.\n",
      "Batch 58 out of 87 batches.\n",
      "Batch 59 out of 87 batches.\n",
      "Batch 60 out of 87 batches.\n",
      "Batch 61 out of 87 batches.\n",
      "Batch 62 out of 87 batches.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 63 out of 87 batches.\n",
      "Batch 64 out of 87 batches.\n",
      "Batch 65 out of 87 batches.\n",
      "Batch 66 out of 87 batches.\n",
      "Batch 67 out of 87 batches.\n",
      "Batch 68 out of 87 batches.\n",
      "Batch 69 out of 87 batches.\n",
      "Batch 70 out of 87 batches.\n",
      "Batch 71 out of 87 batches.\n",
      "Batch 72 out of 87 batches.\n",
      "Batch 73 out of 87 batches.\n",
      "Batch 74 out of 87 batches.\n",
      "Batch 75 out of 87 batches.\n",
      "Batch 76 out of 87 batches.\n",
      "Batch 77 out of 87 batches.\n",
      "Batch 78 out of 87 batches.\n",
      "Batch 79 out of 87 batches.\n",
      "Batch 80 out of 87 batches.\n",
      "Batch 81 out of 87 batches.\n",
      "Batch 82 out of 87 batches.\n",
      "Batch 83 out of 87 batches.\n",
      "Batch 84 out of 87 batches.\n",
      "Batch 85 out of 87 batches.\n",
      "Batch 86 out of 87 batches.\n",
      "Total loss: 9.883835550397635\n",
      "Validation accuracy: 0.6\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning hyperparameters\n",
    "\n",
    "batch_size = 16\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# function to get validation accuracy\n",
    "def get_validation_performance(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "        batch = val_set[i*batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0: continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the number of correctly labeled examples in batch\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "            labels_flat = label_ids.flatten()\n",
    "            num_correct = np.sum(pred_flat == labels_flat)\n",
    "            total_correct += num_correct\n",
    "        \n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_correct / len(val_set)\n",
    "    return avg_val_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# training loop\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    num_batches = int(len(train_set_1)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "      \n",
    "        print(\"Batch \" + str(i) + \" out of \" + str(num_batches) + \" batches.\")\n",
    "        \n",
    "        end_index = min(batch_size * (i+1), len(train_set_1))\n",
    "\n",
    "        batch = train_set_1[i*batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0: continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "\n",
    "        # Clear the previously calculated gradient\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set. Implement this function in the cell above.\n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    val_acc = get_validation_performance(val_set_1)\n",
    "    print(f\"Validation accuracy: {val_acc}\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242342d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab7b33e",
   "metadata": {},
   "source": [
    "### 4) Prediction using title, abstract, and the list of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = []\n",
    "training_label_strings = []\n",
    "\n",
    "validation_inputs = []\n",
    "validation_label_strings = []\n",
    "\n",
    "test_inputs = []\n",
    "test_label_strings = []\n",
    "\n",
    "for training_example in training_data:\n",
    "    \n",
    "    training_input = training_example[0][0] + ' [SEP] ' + training_example[0][2] + ' [SEP] ' + training_example[0][1].replace(' |', ',')\n",
    "    training_inputs.append(training_input)\n",
    "    \n",
    "    training_label_strings.append(training_example[1])\n",
    "    \n",
    "for validation_example in validation_data:\n",
    "    \n",
    "    validation_input = validation_example[0][0] + ' [SEP] ' + validation_example[0][2] + ' [SEP] ' + validation_example[0][1].replace(' |', ',')\n",
    "    validation_inputs.append(validation_input)\n",
    "    \n",
    "    validation_label_strings.append(validation_example[1])\n",
    "    \n",
    "for test_example in test_data:\n",
    "    \n",
    "    test_input = test_example[0][0] + ' [SEP] ' + test_example[0][2] + ' [SEP] ' + test_example[0][1].replace(' |', ',')\n",
    "    test_inputs.append(test_input)\n",
    "    \n",
    "    test_label_strings.append(test_example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_ids, training_attention_masks = tokenize_and_format(training_inputs)\n",
    "validation_input_ids, validation_attention_masks = tokenize_and_format(validation_inputs)\n",
    "test_input_ids, test_attention_masks = tokenize_and_format(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d69e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_IDs = []\n",
    "validation_label_IDs = []\n",
    "test_label_IDs = []\n",
    "\n",
    "for training_label_string in training_label_strings:\n",
    "    training_label_IDs.append(label_string_to_ID[training_label_string])\n",
    "    \n",
    "for validation_label_string in validation_label_strings:\n",
    "    validation_label_IDs.append(label_string_to_ID[validation_label_string])\n",
    "    \n",
    "for test_label_string in test_label_strings:\n",
    "    test_label_IDs.append(label_string_to_ID[test_label_string])\n",
    "    \n",
    "    \n",
    "# Convert the lists into tensors.\n",
    "training_input_ids = torch.cat(training_input_ids, dim=0)\n",
    "training_attention_masks = torch.cat(training_attention_masks, dim=0)\n",
    "training_label_IDs = torch.tensor(training_label_IDs)\n",
    "\n",
    "validation_input_ids = torch.cat(validation_input_ids, dim=0)\n",
    "validation_attention_masks = torch.cat(validation_attention_masks, dim=0)\n",
    "validation_label_IDs = torch.tensor(validation_label_IDs)\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "test_label_IDs = torch.tensor(test_label_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(training_input_ids[i], training_attention_masks[i], training_label_IDs[i]) for i in range(len(training_inputs))]\n",
    "val_set = [(validation_input_ids[i], validation_attention_masks[i], validation_label_IDs[i]) for i in range(len(validation_inputs))]\n",
    "test_set = [(test_input_ids[i], test_attention_masks[i], test_label_IDs[i]) for i in range(len(test_inputs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 20, # The number of output labels.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning hyperparameters\n",
    "\n",
    "batch_size = 16\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                )\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "# function to get validation accuracy\n",
    "def get_validation_performance(val_set):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    num_batches = int(len(val_set)/batch_size) + 1\n",
    "\n",
    "    total_correct = 0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        end_index = min(batch_size * (i+1), len(val_set))\n",
    "\n",
    "        batch = val_set[i*batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0: continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, \n",
    "                                    token_type_ids=None, \n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Calculate the number of correctly labeled examples in batch\n",
    "            pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "            labels_flat = label_ids.flatten()\n",
    "            num_correct = np.sum(pred_flat == labels_flat)\n",
    "            total_correct += num_correct\n",
    "        \n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_correct / len(val_set)\n",
    "    return avg_val_accuracy\n",
    "\n",
    "\n",
    "\n",
    "# training loop\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    num_batches = int(len(train_set)/batch_size) + 1\n",
    "\n",
    "    for i in range(num_batches):\n",
    "      \n",
    "        print(\"Batch \" + str(i) + \" out of \" + str(num_batches) + \" batches.\")\n",
    "        \n",
    "        end_index = min(batch_size * (i+1), len(train_set))\n",
    "\n",
    "        batch = train_set[i*batch_size:end_index]\n",
    "\n",
    "        if len(batch) == 0: continue\n",
    "\n",
    "        input_id_tensors = torch.stack([data[0] for data in batch])\n",
    "        input_mask_tensors = torch.stack([data[1] for data in batch])\n",
    "        label_tensors = torch.stack([data[2] for data in batch])\n",
    "\n",
    "        # Move tensors to the GPU\n",
    "        b_input_ids = input_id_tensors.to(device)\n",
    "        b_input_mask = input_mask_tensors.to(device)\n",
    "        b_labels = label_tensors.to(device)\n",
    "\n",
    "        # Clear the previously calculated gradient\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set. Implement this function in the cell above.\n",
    "    print(f\"Total loss: {total_train_loss}\")\n",
    "    val_acc = get_validation_performance(val_set)\n",
    "    print(f\"Validation accuracy: {val_acc}\")\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
